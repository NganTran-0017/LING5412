{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT LING5412_Final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NganTran-0017/LING5412/blob/main/GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feISDIXHcC77"
      },
      "source": [
        "# **DEEP LEARNING MODELS - PART 3:**\n",
        "**Description**\n",
        "GPT is a transformer-based model that is created by OpenAI in 2019. Similar to BERT, GPT uses attention mechanism to learn context and the most important words in a sentence. The main difference between these 2 models is that GPT is unidirectional, while BERT is bidirectional. However, both models have comparable performances. As GPT was pre-trained on 8 million web pages, it only needs a small dataset to finetune and perform specific tasks like detecting patronizing and condescending language. Therefore, we select GPT-2 for this project with a hope that it can outperform traditional ML models and generates high performance. \n",
        "\n",
        "This notebook load and process text data, and then partition it into training and testing sets. Next, we start processing text data with GPT pretrained tokenizer and embedding words in each training instance into numeric. Since this data is very imbalance, we add an upsampling option to see if the model can improve its performance. If upsampling option is checked above, we'll upsample the training set using SMOTE. \n",
        "\n",
        "Mask paddings are added to the processed training data and then we start finetuning the pretrained GPT model in 3 epochs and 32 batch size. Once the training is completed, we evaluate the model performance on the testing data, annd print the model performance. We also save GPT performance in a text file, whose name indicates whether the data was upsampled or not. This way, we can compare it against the rest of the models in the Visualization notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3_4MDPHP7Lf"
      },
      "source": [
        "#@title Specifying Upsampling Option\n",
        "UPSAMPLE = True #@param {type:\"boolean\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc2pevpoSEud"
      },
      "source": [
        "from torch import nn\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G99qOVzxSOwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2484c6-ba5a-4e8c-efc1-e32e4807cb52"
      },
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix, recall_score\n",
        "# from sklearn.model_selection import cross_validate\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import recall_score, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHh5b74YomXY"
      },
      "source": [
        "# **Loading data**\n",
        "\n",
        "Connects google drive to this notebook to get the dataset, and then unzip it. Then, we load the specified columns (docID, keyword, country, paragraph and label) into the df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvw2VYN_dTtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8402651-fd24-4e5d-8859-e2009fee92dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip \"/content/drive/MyDrive/dontpatrAAonizeme_v1.3.zip\" -d \"/content/drive/MyDrive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "unzip:  cannot find or open /content/drive/MyDrive/dontpatrAAonizeme_v1.3.zip, /content/drive/MyDrive/dontpatrAAonizeme_v1.3.zip.zip or /content/drive/MyDrive/dontpatrAAonizeme_v1.3.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DJ3zR_fCre"
      },
      "source": [
        "# Opening the file from MyDrive\n",
        "file = open(r'/content/drive/MyDrive/dontpatronizeme_v1.3/dontpatronizeme_pcl.tsv')\n",
        "reader = csv.reader(file, delimiter=\"\\t\")\n",
        "data = []\n",
        "for row in reader:\n",
        "  data.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W8pqT5PjG-L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e591a3f0-449b-470d-81e2-8c0b009a9084"
      },
      "source": [
        "# Create a df using the specified columns\n",
        "df = pd.DataFrame(data[5:],  columns = ['docID', 'keyword', 'country', 'paragraph', 'label' ] )\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docID</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@@4703096</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>jm</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@@25567226</td>\n",
              "      <td>in-need</td>\n",
              "      <td>hk</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@@1824078</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>tz</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@@1921089</td>\n",
              "      <td>refugee</td>\n",
              "      <td>tz</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@@40039380</td>\n",
              "      <td>women</td>\n",
              "      <td>ng</td>\n",
              "      <td>Haruna stressed the need for specific approach...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10053</th>\n",
              "      <td>@@16413808</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>my</td>\n",
              "      <td>To me , I am always mindful that we are dealin...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10054</th>\n",
              "      <td>@@8676630</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>jm</td>\n",
              "      <td>Other themes included promoting the inclusion ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10055</th>\n",
              "      <td>@@7688552</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>gb</td>\n",
              "      <td>It came as the CDU was also humiliated by the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10056</th>\n",
              "      <td>@@4916290</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>in</td>\n",
              "      <td>Those were only days of helplessness , she say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10057</th>\n",
              "      <td>@@2973614</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>They include a community college student , a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10058 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            docID  ... label\n",
              "0       @@4703096  ...     0\n",
              "1      @@25567226  ...     0\n",
              "2       @@1824078  ...     4\n",
              "3       @@1921089  ...     0\n",
              "4      @@40039380  ...     0\n",
              "...           ...  ...   ...\n",
              "10053  @@16413808  ...     4\n",
              "10054   @@8676630  ...     0\n",
              "10055   @@7688552  ...     0\n",
              "10056   @@4916290  ...     0\n",
              "10057   @@2973614  ...     0\n",
              "\n",
              "[10058 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtakLrrIoo9_"
      },
      "source": [
        "# **Exploring data**\n",
        "\n",
        "Get the length of each data instance and plot its histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BfIKFam55W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d407477-289a-47dd-a61c-96a021a35476"
      },
      "source": [
        "# Length of text\n",
        "def length (txt):\n",
        "  length = len(txt.split())\n",
        "  return length\n",
        "\n",
        "txt_length = df['paragraph'].apply(lambda x: length(x))\n",
        "txt_length.sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3534    1519\n",
              "6266    1095\n",
              "8519    1040\n",
              "4613     772\n",
              "8819     729\n",
              "        ... \n",
              "1930       4\n",
              "1385       3\n",
              "7375       3\n",
              "5112       3\n",
              "5742       0\n",
              "Name: paragraph, Length: 10058, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKhQ4cW79T5o"
      },
      "source": [
        "None of the column contains missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlKftt3JVk-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7a6564-c672-4f9b-a658-f7d70379ddcb"
      },
      "source": [
        "#checking for missing values\n",
        "print('Is null: \\n', df.isnull().sum() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is null: \n",
            " docID        0\n",
            "keyword      0\n",
            "country      0\n",
            "paragraph    0\n",
            "label        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u22WnF-6vsN1"
      },
      "source": [
        "There are 5 labels in this dataset. The label number represents the degree of patronizing and condescending language (PCL).  Label 0 are sentences that do not contain patronizing nor condescending language, where as Label 4 are sentences with highly PCL. Based on the value counts below, the majority of data is negative with a label 0, whereas only 946 records are positive. Positive data contain labels from 1 to 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwca4mOjwy5V"
      },
      "source": [
        "In this project, we choose task 1 that is a binary classification of PCL. Therefore, we convert the labels into 0 and 1, where 0 means negative and 1 means positive. The negative data contain label 0 originally, and the positive data contain labels 1 to 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQyvG1B0pvEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "05beb93f-2f32-4b56-bbe8-9e2db9b59f07"
      },
      "source": [
        "# Convert label data type to string\n",
        "df['label'] = df['label'].astype(str)\n",
        "df['label']\n",
        "\n",
        "# One hot encoding labels\n",
        "label_dic = {'0':0,\n",
        "             '1':0,\n",
        "             '2':1,\n",
        "             '3':1,\n",
        "             '4':1}\n",
        "df['label'] = df['label'].map(label_dic)\n",
        "print(df['label'].value_counts())\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    9112\n",
            "1     946\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcAMX5reo0e1"
      },
      "source": [
        "# **Data Partition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_XQu6iX0BOO"
      },
      "source": [
        "Once the data is thoroughly explored, we proceed to partition the shuffled data into training and testing sets with a ratio of 80-20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvza5K7YbJ4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e604a0b5-b29d-4bbf-aeb1-737e83b627b0"
      },
      "source": [
        "# Splitting the data into training (80%) and test set(20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['paragraph']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, train_size = 0.8, random_state = 42, shuffle = True, stratify=y)\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)\n",
        "print(y_train.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (8046,) (8046,)\n",
            "Shapes of X_test, y_test:  (2012,) (2012,)\n",
            "0    7289\n",
            "1     757\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjcbr_EtTt8_"
      },
      "source": [
        "# **Create helper functions for printing and recording performance measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jzrGXGc4whO"
      },
      "source": [
        "This part creates 2 helper function, where printing_eval_scores is responsible for printing out the model performance and get_roc_curve is responsible for extracting different metrics such as false positive rate (FPR), recall, macro-f1 scores and auc score. These 2 functions take the ground truth labels and predicted labels as inputs.\n",
        "\n",
        "Since the data is very imbalanced, we decide to use macro-F1 score as a standard metric to compare among the candidate models. Macro-F1 score takes both major class and minor class into account regardless of their sizes. Therefore, using this metric will give us a more precise baseline to compare among the models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJdUeuNUdmij"
      },
      "source": [
        "# Printing model performance \n",
        "def printing_eval_scores (y_true, y_pred):\n",
        "  print('accuracy score: {}'.format(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
        "  print('precision score: {}'.format(sklearn.metrics.precision_score(y_true, y_pred, average = 'macro', zero_division=1)))\n",
        "  print('recall score: {}'.format(sklearn.metrics.recall_score(y_true, y_pred,  average = 'macro', zero_division=1)))\n",
        "  print('F1 score: {}'.format(f1_score(y_true, y_pred,  average = 'macro', zero_division=1)))\n",
        "  print('\\nConfusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
        "  print('\\n', classification_report(y_true, y_pred))\n",
        "\n",
        "# Get the measurements of ROC curve for each model\n",
        "def get_roc_cuve (y_true, y_pred):\n",
        "  # Get arrays of FPR and recall using roc_curve\n",
        "  FPR, recall, threshold = sklearn.metrics.roc_curve(y_true, y_pred)\n",
        "\n",
        "  # Get testing accuracy:\n",
        "  acc = accuracy_score( y_test,y_pred)\n",
        "\n",
        "  # Get testing macro-f1:\n",
        "  f1 = f1_score(y_test, y_pred,  average = 'macro', zero_division=1)\n",
        "\n",
        "  # Get auc score\n",
        "  auc = sklearn.metrics.auc(FPR, recall)\n",
        "  roc = {'fpr': FPR, 'tpr': recall, 'auc': auc, 'accuracy': acc, 'macro-F1': f1}\n",
        "  return roc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRbJv7mZK6F"
      },
      "source": [
        "# **GPT-2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPecGk4FVEc3"
      },
      "source": [
        "**Get maximum length of a sentence**\n",
        "\n",
        " If it's greater than 512, MAX_LEN is set to be 225. We tried to set it with 512, but we run out of GPU memory, so we decide to set it as 225."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJUNynZyYSLS",
        "outputId": "7a267912-9090-4805-e888-b7309f2deea9"
      },
      "source": [
        "# get max len in tokenized train text to set the tokens length in the next step\n",
        "MAX_LEN = max(map(len, X_train))  # \n",
        "print('MAX LEN of trainning sentence is:', MAX_LEN, '\\nMAX LEN > 512 is ', MAX_LEN>512)\n",
        "\n",
        "# Update MAX LEN if it's > 512, set it to be 225 \n",
        "## 512 is is the maximum seq len of BERT_BASE. But we cannot allow the seq len to be 512 since we'll run out of GPU memory --> Use max len of 225\n",
        "MAX_LEN = 225 if MAX_LEN > 512 else MAX_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX LEN of trainning sentence is: 8779 \n",
            "MAX LEN > 512 is  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIoX7sMSGepe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239f0eb6-0f78-4188-bc2e-3c8771b465b4"
      },
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w48ScPVYZNpN",
        "outputId": "f18ba045-9f28-4ecc-9173-571bdbc573a3"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "\n",
        "# Load GPT2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO0mOgye_R_x"
      },
      "source": [
        "Since we use a MAX_LEN of 225, some sentences will be shorter than that. Therefore, we need to embed its empty space on the right after tokenizing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxXKH8iqZZOn"
      },
      "source": [
        "# Padding sequences from the right to MAX_LEN (225) and tokenize train set\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "train_tokens = tokenizer(X_train.to_list(), return_tensors='pt', truncation=True, padding=True, max_length = MAX_LEN)\n",
        "test_tokens  = tokenizer(X_test.to_list(),  return_tensors='pt', truncation=True, padding=True, max_length = MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hle4w3cZHfP7",
        "outputId": "6a581ce1-c04b-42ca-e338-4eb699ab0466"
      },
      "source": [
        "# This is the embedded word vector of each training instance\n",
        "train_tokens.input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3347, 22974,   284,  ..., 50256, 50256, 50256],\n",
              "        [ 1858,   705,    82,  ..., 50256, 50256, 50256],\n",
              "        [  464, 12746,   705,  ..., 50256, 50256, 50256],\n",
              "        ...,\n",
              "        [24035,   351,   262,  ..., 50256, 50256, 50256],\n",
              "        [10294,   837,   607,  ..., 50256, 50256, 50256],\n",
              "        [  464,  4599,  8474,  ..., 50256, 50256, 50256]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52fjlJ-m98uA"
      },
      "source": [
        "Upsampling option is available at the top of this notebook. If var UPSAMPLE is checked, the data will be upsampled using SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyR_C7bgH2FC",
        "outputId": "b5b253d2-cc96-43ec-e68f-8b76311c4a30"
      },
      "source": [
        "# If Upsampling option for GPT is on, then upsample data using SMOTE first.\n",
        "# Then, convert List of words to list of numbers. (Words are replaced by their index in the dictionary)\n",
        "if UPSAMPLE:\n",
        "  oversampler = SMOTE(random_state=42)\n",
        "  train_tokens_ids, train_labels = oversampler.fit_resample(train_tokens.input_ids, y_train)\n",
        "else:\n",
        "  train_tokens_ids = train_tokens.input_ids\n",
        "  train_labels = y_train\n",
        "\n",
        "# Do the same thing to the test set\n",
        "test_tokens_ids = test_tokens.input_ids\n",
        "\n",
        "train_tokens_ids.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14578, 225), (14578,))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V2ao-iQZX-t"
      },
      "source": [
        "# Mask the paddings with 0 and words with 1\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvmaGH-QczkH"
      },
      "source": [
        "# Define GPT binary classifier\n",
        "class GTP2BinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(GTP2BinaryClassifier, self).__init__()\n",
        "        self.gtp2 = GPT2ForSequenceClassification.from_pretrained('microsoft/DialoGPT-small')\n",
        "      \n",
        "    def train_m(self,x,y,train_mask,epochs,batchsize):\n",
        "      train_tokens_tensor = torch.tensor(x)\n",
        "      train_y_tensor = torch.tensor(y.reshape(-1, 1)).long()\n",
        "      train_masks_tensor = torch.tensor(train_mask)\n",
        "\n",
        "      train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "      train_sampler = RandomSampler(train_dataset)\n",
        "      train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batchsize) \n",
        "\n",
        "\n",
        "      # param_optimizer = list(self.gtp2.parameters()) \n",
        "      # optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "      optimizer = Adam(self.gtp2.parameters(), lr=5e-5)\n",
        "      for epoch_num in range(epochs):\n",
        "          self.gtp2.train() # Training Flag\n",
        "          train_loss = 0\n",
        "          for step_num, batch_data in enumerate(train_dataloader):\n",
        "              \n",
        "              # Load batch on device memory\n",
        "              token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "              self.zero_grad()\n",
        "\n",
        "              # Get the output of the model for provided input\n",
        "              outputs = self.gtp2(token_ids,attention_mask=masks,labels=labels)\n",
        "              loss, logits = outputs[:2]\n",
        "              # logits = self(token_ids, masks)\n",
        "              \n",
        "              # Total Loss\n",
        "              train_loss += loss.item()\n",
        "              \n",
        "              # Backward pass the loss\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(self.gtp2.parameters(), 1.0)\n",
        "              \n",
        "              optimizer.step()\n",
        "              logits = logits.cpu().detach().numpy()\n",
        "\n",
        "              clear_output(wait=True)\n",
        "        \n",
        "              print('Epoch: ', epoch_num + 1)\n",
        "              print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_labels) / batchsize, train_loss / (step_num + 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mybbry1QczgA",
        "outputId": "aa487fc8-1d85-445f-d4ee-061db2d2cf47"
      },
      "source": [
        "# Initiate GPT Classifier using cuda\n",
        "gtp_clf = GTP2BinaryClassifier()\n",
        "gtp_clf = gtp_clf.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/DialoGPT-small were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at microsoft/DialoGPT-small and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt8MVtlSczc3",
        "outputId": "ce41414b-a5fd-4fcf-bd0c-84f2464eef32"
      },
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SZ = 32\n",
        "\n",
        "# Configure the Padding token id\n",
        "gtp_clf.gtp2.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Train GPT\n",
        "gtp_clf.train_m(train_tokens_ids, train_labels.to_numpy(), train_masks, EPOCHS, BATCH_SZ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  3\n",
            "\r455/455.5625 loss: 0.021907716119517095 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ZPw8bBJult",
        "outputId": "67e5f43b-1c3b-4444-a824-23f830d0c134"
      },
      "source": [
        "train_tokens_ids.shape, train_labels.to_numpy().shape, len(train_masks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14578, 225), (14578,), 14578)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI61tMiaeZ_w"
      },
      "source": [
        "**Evaluate on Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0B4ycuLczXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21eb800-c67a-4832-de08-71289f5960b2"
      },
      "source": [
        "## Converting test token ids, test labels and test masks to a tensor and the create a tensor dataset out of them.\n",
        "# Convert token ids to tensor \n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "\n",
        "# Convert labels to tensors\n",
        "test_y_tensor = torch.tensor( y_test.to_numpy().reshape(-1, 1) ).long()\n",
        "\n",
        "# Convert masks to tensor\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "# Load Token, token mask and label into Dataloader\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "\n",
        "# Define sampler\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "\n",
        "# Define test data loader\n",
        "test_dataloader = DataLoader(test_dataset, sampler = test_sampler, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md_tqaatfUfZ"
      },
      "source": [
        "# Evaluate Model\n",
        "gtp_clf.eval() # Define eval\n",
        "gpt_predicted = [] # Store Result\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        outputs = gtp_clf.gtp2(token_ids, attention_mask=masks, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        numpy_logits = logits.detach().cpu().numpy()\n",
        "        # ----------------------------------------------------------------\n",
        "        gpt_predicted +=list(numpy_logits.argmax(axis=-1).flatten().tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VhTgpr-hmhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f244437-34a1-41cd-cc83-d32440b742ae"
      },
      "source": [
        "rocs = {}\n",
        "# Get ROC curve measurements\n",
        "rocs['GPT'] = get_roc_cuve(y_test, gpt_predicted)\n",
        "\n",
        "# Prin performance\n",
        "print('----------------------------GPT performance---------------------------')\n",
        "printing_eval_scores(y_test, gpt_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------GPT performance---------------------------\n",
            "accuracy score: 0.9100397614314115\n",
            "precision score: 0.9044157577060161\n",
            "recall score: 0.9100397614314115\n",
            "F1 score: 0.717525982704311\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1746   77]\n",
            " [ 104   85]]\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      1823\n",
            "           1       0.52      0.45      0.48       189\n",
            "\n",
            "    accuracy                           0.91      2012\n",
            "   macro avg       0.73      0.70      0.72      2012\n",
            "weighted avg       0.90      0.91      0.91      2012\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nE2wU_GNCLZ"
      },
      "source": [
        "#**Visualize all models with ROC curves**\n",
        "\n",
        "The model performances are visualized through an overlaid ROC curves. In this plot, the higher recall and the lower FPR that the model can achieve, the better that model is. A model that randomly classify data is represented as a straight dotted line in black."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLSNk1uWO5KD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "54a07b16-3374-4c3d-a609-cb64660087ae"
      },
      "source": [
        "def graph_multi_ROC (rocs):\n",
        "  # Set color for each model\n",
        "  colors = {'LGBM': 'lightcoral','LR': 'darkorange', 'SVM':'lime', 'NB': 'steelblue',\n",
        "            'XGB': 'purple','DT': 'magenta','RF': 'deeppink','KNN': 'darkturquoise',\n",
        "            'BERT': 'darkred', 'GPT': 'blue'}\n",
        "  # Set marker for each model          \n",
        "  markers = {'LGBM':'1--','LR': 'v--', 'SVM': '^--', 'XGB': '*--', 'DT': 'o--', 'RF': '+--', 'KNN': '.--', 'NB': 'x--', 'BERT':'<--', 'GPT': '>--'}\n",
        "  \n",
        "  plt.figure(figsize=(9,6))\n",
        "  for model in rocs:\n",
        "    plt.plot( rocs[model]['fpr'], rocs[model]['tpr'], markers[model], color=colors[model], label= model+' - AUC=' + str(rocs[model]['auc'].round(3)) )\n",
        "  \n",
        "  plt.plot([0,1], [0,1], 'k--', label='Random Chances')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.02])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  plt.legend(loc='lower right') \n",
        "  plt.title( 'ROC Curves of all models')\n",
        "  plt.show()\n",
        "\n",
        "graph_multi_ROC(rocs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUMd3xudZj5a"
      },
      "source": [
        "# Export performance to a txt file\n",
        "\n",
        "# Set file name according to Upsampling option\n",
        "if UPSAMPLE == 1: name = 'GPT_SMOTE'\n",
        "else: name = 'GPT'\n",
        "\n",
        "txtfile = open( name + '.txt','w')\n",
        "txtfile.write(name + '='+ str(rocs['GPT'])+'\\n')\n",
        "\n",
        "txtfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XSS8eilOyuO",
        "outputId": "34f676e4-b4ae-4a1f-b604-0ac06e494fe6"
      },
      "source": [
        "rocs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GPT': {'accuracy': 0.9100397614314115,\n",
              "  'auc': 0.7037486903093046,\n",
              "  'fpr': array([0.        , 0.04223807, 1.        ]),\n",
              "  'macro-F1': 0.717525982704311,\n",
              "  'tpr': array([0.        , 0.44973545, 1.        ])}}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}